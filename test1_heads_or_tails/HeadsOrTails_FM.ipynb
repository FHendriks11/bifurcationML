{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from flow_matching/examples/standalone_flow_matching.ipynb from the Facebook Flow Matching github repository (https://github.com/facebookresearch/flow_matching/blob/main/examples/standalone_flow_matching.ipynb).\n",
    "\n",
    "Attempts to turn a standard Gaussian distribution into a distribution with two sharp peaks at -X and +X, where X is the amount you bet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open training data\n",
    "with open('../data/HeadsOrTails_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data_tr = data['data_tr']\n",
    "data_te = data['data_te']\n",
    "x_std = data['x_std']\n",
    "x_m = data['x_m']\n",
    "y_std = data['y_std']\n",
    "y_m = data['y_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(nn.Module):\n",
    "    def __init__(self, dim: int = 1, cond: int = 1, h: int = 64):\n",
    "        # dim: dimension of data sample\n",
    "        # cond: dimension of the thing we're conditioning on (the bet in this case)\n",
    "        # h: hidden layer size\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(cond + dim + 1, h), nn.ELU(),\n",
    "            nn.Linear(h, h), nn.ELU(),\n",
    "            nn.Linear(h, h), nn.ELU(),\n",
    "            nn.Linear(h, dim))\n",
    "\n",
    "    def forward(self, t: Tensor, x_t: Tensor, cond: Tensor) -> Tensor:\n",
    "        return self.net(torch.cat((t, x_t, cond), -1))\n",
    "\n",
    "    def step(self, x_t: Tensor, t_start: Tensor, t_end: Tensor, cond: Tensor) -> Tensor:\n",
    "        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1)\n",
    "\n",
    "        return (x_t + (t_end - t_start)\n",
    "                * self(\n",
    "                    t=t_start + (t_end - t_start) / 2,\n",
    "                    x_t= x_t + self(x_t=x_t, t=t_start, cond=cond) * (t_end - t_start) / 2,\n",
    "                    cond=cond\n",
    "                       )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('cuda available')\n",
    "    # mlflow.log_param('device', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('cuda not available')\n",
    "    # mlflow.log_param('device', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_tr, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_te, batch_size=100000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Flow().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "MSE_loss = []\n",
    "for i in range(10000):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    loss_temp = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        x_1 = batch[:, [1]]\n",
    "        cond = batch[:, [0]]\n",
    "        x_0 = torch.randn_like(x_1).to(device)\n",
    "        t = torch.rand(len(x_1), 1).to(device)\n",
    "\n",
    "        x_t = (1 - t) * x_0 + t * x_1\n",
    "        dx_t = x_1 - x_0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(flow(t=t, x_t=x_t, cond=cond), dx_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_temp.append(loss.item())\n",
    "\n",
    "    if i == 1000:\n",
    "        optimizer = torch.optim.Adam(flow.parameters(), 1e-5)\n",
    "    MSE_loss.append(np.mean(loss_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(MSE_loss)\n",
    "# plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot smoothened loss\n",
    "plt.figure()\n",
    "plt.plot(np.convolve(MSE_loss, np.ones(100)/100, mode='valid'))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "n_steps = 128\n",
    "\n",
    "fig, axes = plt.subplots(1, n_steps//2 + 1, figsize=(20, 4), sharex=True, sharey=True)\n",
    "\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1).to(device)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect('equal')\n",
    "    # ax.axline((0,0), (1,1), c='tab:red')\n",
    "    # ax.axline((0,0), (-1,1), c='tab:red')\n",
    "\n",
    "for j in range(10):  # 10 predictions per data point\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        x = torch.randn_like(batch[:, [1]]).to(device)  # initial gaussian noise\n",
    "        cond = batch[:, [0]]  # conditioning on the bet\n",
    "        bet = cond.cpu()*x_std+x_m\n",
    "        pred = x.cpu().detach()[:, 0]*y_std+y_m\n",
    "        real = batch[:, 1].cpu()*y_std+y_m\n",
    "        axes[0].scatter(bet, pred, s=1, label='_'*j+'predicted', c='tab:orange')\n",
    "        axes[0].scatter(bet, real, s=1, label='_'*j+'real', c='tab:blue')\n",
    "        axes[0].set_title(f't = {time_steps[0]:.2f}')\n",
    "        axes[0].legend()\n",
    "        axes[0].set_xlim(-100.0, 100.0)\n",
    "        axes[0].set_ylim(-100.0, 100.0)\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], cond=cond)\n",
    "\n",
    "            if i % 2 == 1:\n",
    "                bet = cond.cpu()*x_std+x_m\n",
    "                pred = x.cpu().detach()[:, 0]*y_std+y_m\n",
    "                real = batch[:, 1].cpu()*y_std+y_m\n",
    "                axes[i//2 + 1].scatter(bet, real, s=1, label='real', c='tab:blue')\n",
    "                axes[i//2 + 1].scatter(bet, pred, s=1, label='predicted', c='tab:orange')\n",
    "                                    # , s=1, c='tab:blue', alpha=0.5)\n",
    "                axes[i//2 + 1].set_title(f't = {time_steps[i + 1]:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result at t=1 only\n",
    "fig, ax = plt.subplots(figsize=(4,3), dpi=200)\n",
    "for batch in test_loader:\n",
    "    batch = batch.to(device)\n",
    "    cond = batch[:, [0]]  # conditioning on the bet\n",
    "    bet = cond.cpu()*x_std+x_m\n",
    "    real = batch[:, 1].cpu()*y_std+y_m\n",
    "    for j in range(10):  # 10 predictions per data point\n",
    "        x = torch.randn_like(batch[:, [1]]).to(device)  # initial gaussian noise\n",
    "        for i in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], cond=cond)\n",
    "\n",
    "        pred = x.cpu().detach()[:, 0]*y_std+y_m\n",
    "        ax.scatter(bet, pred, s=1, label='_'*j+'predicted', c='tab:orange')\n",
    "        ax.scatter(bet, real, s=1, label='_'*j+'true', c='tab:blue')\n",
    "ax.legend()\n",
    "ax.set_ylabel('winnings (€)')\n",
    "ax.set_xlabel('bet (€)')\n",
    "ax.set_aspect('equal')\n",
    "fig.subplots_adjust(left=0.2, bottom=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram for bet = €50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of the histograms\n",
    "n_steps = 32\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1).to(device)\n",
    "print(len(time_steps))\n",
    "inds_to_plot = np.linspace(0, n_steps, 5).astype(int)\n",
    "print(inds_to_plot)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(inds_to_plot), figsize=(15, 3), sharex=True, sharey=True)\n",
    "\n",
    "N = 10000\n",
    "x = torch.randn(N, 1).to(device)  # initial gaussian noise\n",
    "cond = (torch.ones((N, 1), dtype=torch.float32, device=device)*50-data['x_m'])/data['x_std']  # conditioning on the bet\n",
    "\n",
    "bins = np.linspace(-150, 150, 50)\n",
    "axes[0].hist(x.cpu().detach()[:, 0]*data['y_std']+data['y_m'],\n",
    "             bins=bins, density=True)\n",
    "axes[0].set_title(f't = {time_steps[0]:.2f}')\n",
    "axes[0].set_ylabel('probability density')\n",
    "axes[0].set_xlabel('predicted winnings (€)')\n",
    "\n",
    "fig.suptitle(f'Samples from the flow, bet = 50€, {n_steps} steps')\n",
    "\n",
    "for ax in axes:\n",
    "    # ax.set_yscale('log')\n",
    "    ax.axvline(50, color='r', linestyle='dashed')\n",
    "    ax.axvline(-50, color='r', linestyle='dashed')\n",
    "    # ax.vlines([50, -50], 0, 100, colors='r', linestyles='dashed', label='possible ground truth winnings')\n",
    "\n",
    "to_plot = 1\n",
    "for i in range(1,n_steps+1):\n",
    "    print(i, to_plot)\n",
    "    x = flow.step(x_t=x, t_start=time_steps[i-1], t_end=time_steps[i], cond=cond)\n",
    "\n",
    "    if i == inds_to_plot[to_plot]:\n",
    "        axes[to_plot].hist(\n",
    "                            x.cpu().detach()[:, 0]*data['y_std']+data['y_m'],\n",
    "                            bins=bins, density=True,)\n",
    "        axes[to_plot].set_title(f't = {time_steps[i]:.2f}')\n",
    "        axes[to_plot].set_xlabel('predicted winnings (€)')\n",
    "        to_plot += 1\n",
    "\n",
    "fig.subplots_adjust(top=0.8, bottom=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Result only\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "bins = np.linspace(-75, 75, 40)\n",
    "preds = (x.cpu().detach()[:, 0]*data['y_std']+data['y_m']).numpy()\n",
    "ax.hist(preds, bins=bins, density=True)\n",
    "# ax.set_title(f'Final distribution for bet of 50€')\n",
    "ax.set_xlabel('predicted winnings (€)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.axvline(50, color='r', linestyle='dashed')\n",
    "ax.axvline(-50, color='r', linestyle='dashed')\n",
    "# fig.suptitle(f'Samples from the flow, bet = 50€, {n_steps} steps')\n",
    "fig.subplots_adjust(top=0.8, left=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(preds < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(preds > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "n_steps = 128\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1).to(device)\n",
    "\n",
    "flow.eval()\n",
    "for batch in test_loader:\n",
    "    batch = batch.clone().to(device)\n",
    "\n",
    "    preds = np.zeros((len(batch), 100))  # create 100 predictions per data point\n",
    "\n",
    "    cond = batch[:, [0]]  # conditioning on the bet\n",
    "    for i in range(100):  # make 100 predictions for each data point\n",
    "        x = torch.randn_like(batch[:, [1]]).to(device).clone()  # initial gaussian noise\n",
    "        for j in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[j], t_end=time_steps[j + 1], cond=cond)\n",
    "        preds[:, i] = x.clone().cpu().detach().numpy()[:, 0]*y_std+y_m\n",
    "\n",
    "    reals = batch[:, 1:].cpu().detach().numpy()*y_std + y_m\n",
    "\n",
    "    print(preds.shape)\n",
    "    print(reals.shape)\n",
    "\n",
    "    wd = []\n",
    "    for pred, real in zip(preds, reals):  # iterate over all data points (as far as I know, this cannot be batched)\n",
    "        wd.append(wasserstein_distance(pred, real))\n",
    "\n",
    "print('Mean Wasserstein distance between real and predicted:', np.mean(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bifurc_env4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
