{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch_geometric as tg\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/FourNodeGraph_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(key, value.size())\n",
    "    elif isinstance(value, list):\n",
    "        print(key, len(value))\n",
    "    else:\n",
    "        print(key, value)\n",
    "\n",
    "data_tr = data['data_tr']\n",
    "data_te = data['data_te']\n",
    "x_m = data['x_m']\n",
    "y_m = data['y_m']\n",
    "x_std = data['x_std']\n",
    "y_std = data['y_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_attr = torch.FloatTensor([1, 1, -1, -1, -1, -1, 1, 1.0]).reshape(-1, 1)\n",
    "edge_attr = torch.FloatTensor([1.0]*8).reshape(-1, 1)\n",
    "# edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in data_tr:\n",
    "    graph.edge_attr = edge_attr\n",
    "for graph in data_te:\n",
    "    graph.edge_attr = edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tg.loader.DataLoader(data_tr, batch_size=64)\n",
    "test_loader = tg.loader.DataLoader(data_te, batch_size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('cuda available')\n",
    "    # mlflow.log_param('device', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('cuda not available')\n",
    "    # mlflow.log_param('device', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMessagePassingLayer(MessagePassing):\n",
    "    \"\"\"message passing layer that updates both node and edge embeddings.\n",
    "    first, the node embedding is updated based on the previous node embedding and the message received from neighboring nodes. these messages are based on the embedding of the source node and the edge attributes.\n",
    "    second, the edge embedding is updated based on the previous edge embedding and the node embeddings of the source and target node.\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    messagepassing : [type]\n",
    "        [description]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, node_in, edge_in, message_size, node_out, edge_out):\n",
    "\n",
    "        \"\"\"initialize layer\n",
    "\n",
    "        parameters\n",
    "        ----------\n",
    "        node_in : int\n",
    "            previous node embedding size\n",
    "        edge_in: int\n",
    "            previous edge embedding size\n",
    "        message_size : int\n",
    "            size of the message\n",
    "        node_out : int\n",
    "            node embedding size after updating\n",
    "        edge_out: in\n",
    "            edge embedding size after updating\n",
    "        \"\"\"\n",
    "        super().__init__(aggr='add')\n",
    "        self.mlp_message = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(2*node_in + edge_in, message_size),\n",
    "                        torch.nn.LeakyReLU(),\n",
    "                        torch.nn.Linear(message_size, message_size),\n",
    "                        torch.nn.LeakyReLU())\n",
    "        self.mlp_update = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(node_in + message_size,\n",
    "                                        node_out),\n",
    "                        torch.nn.LeakyReLU(),\n",
    "                        torch.nn.Linear(node_out, node_out))\n",
    "        self.mlp_edge = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(edge_in + 2*node_in, edge_out),\n",
    "                        torch.nn.LeakyReLU(),\n",
    "                        torch.nn.Linear(edge_out, edge_out))\n",
    "\n",
    "        # print('__init__')\n",
    "        # self.lin1 = torch.nn.linear(node_in, node_out)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        parameters\n",
    "        ----------\n",
    "        x : torch.tensor, shape [n, node_in]\n",
    "            current node embedding for each of the n nodes\n",
    "        edge_index : torch.tensor, shape [2, e]\n",
    "            indices of all edges\n",
    "        edge_attr : torch.tensor, shape [e, edge_in]\n",
    "            edge_attributes of each of the e edges\n",
    "        \"\"\"\n",
    "        # print('forward')\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr), self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def edge_update(self, edge_index, x_i, x_j, edge_attr):\n",
    "        # print('edge_updater')\n",
    "        temp = torch.cat((edge_attr, x_i, x_j), dim=1)\n",
    "        # print('edge_update, temp.shape:', temp.shape)\n",
    "\n",
    "        return self.mlp_edge(temp)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        parameters\n",
    "        ----------\n",
    "        x_j : torch.tensor, shape [e, node_in]\n",
    "            node embeddings of source nodes\n",
    "        edge_attr : torch.tensor, shape [e, edge_in]\n",
    "            [description]\n",
    "        \"\"\"\n",
    "        # print('message')\n",
    "        # print('x_j.shape, edge_attr.shape:', x_j.shape, edge_attr.shape)\n",
    "        temp = torch.cat((x_i, x_j, edge_attr), dim=1)\n",
    "        return self.mlp_message(temp)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # print('update')\n",
    "        # print('x.shape, aggr_out.shape:', x.shape, aggr_out.shape)\n",
    "        temp = torch.cat((x, aggr_out), dim=1)\n",
    "        # temp = x\n",
    "        return self.mlp_update(temp)\n",
    "\n",
    "\n",
    "class MyGNN(torch.nn.Module):\n",
    "    def __init__(self, use_edge_weight=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = MyMessagePassingLayer(3, 1, 0, 16, 16)\n",
    "        # self.batchnorm_x = torch.nn.BatchNorm1d(16)\n",
    "        # self.batchnorm_e = torch.nn.BatchNorm1d(16)\n",
    "        self.conv2 = MyMessagePassingLayer(16, 16, 16, 16, 16)\n",
    "        # self.batchnorm2_x = torch.nn.BatchNorm1d(16)\n",
    "        # self.batchnorm2_e = torch.nn.BatchNorm1d(16)\n",
    "        self.conv3 = MyMessagePassingLayer(16, 16, 16, 1, 0)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        # convolutional part\n",
    "        x, edge_attr = self.conv1(x, edge_index, edge_attr=edge_attr)\n",
    "        # x, edge_attr = self.batchnorm_x(x), self.batchnorm_e(edge_attr)\n",
    "        x, edge_attr = F.leaky_relu(x), F.leaky_relu(edge_attr)\n",
    "        x, edge_attr = self.conv2(x, edge_index, edge_attr=edge_attr)\n",
    "        # x, edge_attr = self.batchnorm2_x(x), self.batchnorm2_e(edge_attr)\n",
    "        x, edge_attr = F.leaky_relu(x), F.leaky_relu(edge_attr)\n",
    "        x, _ = self.conv3(x, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(nn.Module):\n",
    "    def __init__(self):\n",
    "        # dim: dimension of data sample\n",
    "        # cond: dimension of the thing we're conditioning on (the bet in this case)\n",
    "        # h: hidden layer size\n",
    "        super().__init__()\n",
    "        super(Flow, self).__init__()\n",
    "        self.GNN = MyGNN()\n",
    "\n",
    "    def forward(self, t, x_t, batch) -> Tensor:\n",
    "        batch2 = batch.clone()\n",
    "        node_attr = batch2.x\n",
    "        # print('t.shape', t.shape)\n",
    "        # print('x_t.shape', x_t.shape)\n",
    "        # print('node_attr.shape', node_attr.shape)\n",
    "        batch2.x = torch.cat((node_attr, t, x_t), dim=-1)\n",
    "        # print('batch2.x.shape', batch2.x.shape)\n",
    "\n",
    "        node_attr = self.GNN(batch2)\n",
    "        # print('modified node_attr.shape', node_attr.shape)\n",
    "\n",
    "        return node_attr\n",
    "\n",
    "    def step(self, x_t: Tensor, t_start: Tensor, t_end: Tensor, batch) -> Tensor:\n",
    "        # t: float, current time\n",
    "        # t_end: float, end time\n",
    "        # x_t: shape [batch size, 2], current position\n",
    "        # cond: shape [batch size, 2], initial position\n",
    "\n",
    "        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1)\n",
    "\n",
    "        # print('x_t.shape', x_t.shape)\n",
    "        # print('t_start.shape', t_start.shape)\n",
    "        # print('t_end.shape', t_end.shape)\n",
    "        # print('cond.shape', cond.shape)\n",
    "\n",
    "\n",
    "        return (x_t + (t_end - t_start)\n",
    "                * self(\n",
    "                    t=t_start + (t_end - t_start) / 2,\n",
    "                    x_t= x_t + self(x_t=x_t, t=t_start, batch=batch) * (t_end - t_start) / 2,\n",
    "                    batch=batch\n",
    "                       )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Flow().to(device)\n",
    "print(flow)\n",
    "\n",
    "n_params = sum(p.numel() for p in flow.parameters())\n",
    "print('Total nr of parameters:', n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSELoss_allTargets(pred, target, batch, return_indices=False):\n",
    "    \"\"\"MSE loss applied on all possible targets, then taking the minimum per graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : torch tensor, [N, f]\n",
    "        prediction per node, N = total nr of nodes, f = nr of predicted features\n",
    "    target : torch tensor, [N, f, a]\n",
    "        all possible targets, N = total nr of nodes, f = nr of predicted features, a = nr of possible alternatives\n",
    "    batch : torch tensor, [N, ]\n",
    "        graph that each node belongs to\n",
    "    return_indices : bool, optional\n",
    "        whether to return the indices of the alternatives giving the minimum loss, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch tensor, [1,]\n",
    "        MSE loss, using the closest alternative for each graph\n",
    "    \"\"\"\n",
    "    # sum square error per node per alternative (resulting shape: [N, a])\n",
    "    SE = torch.sum((pred.unsqueeze(-1) - target)**2, dim=1)\n",
    "    # sum square error per graph per alternative (resulting shape: [G, a], with G the nr of graphs)\n",
    "    SE = tg.nn.global_add_pool(SE, batch=batch)\n",
    "    # take the minimum error per graph\n",
    "    SE_min, inds = torch.min(SE, axis=-1)\n",
    "\n",
    "    # take mean over entire batch\n",
    "    MSE = torch.sum(SE_min)/(pred.numel())\n",
    "\n",
    "    if return_indices:\n",
    "        return MSE, inds\n",
    "    else:\n",
    "        return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_matching = True\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "MSE_loss = []\n",
    "for i in range(1000):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    loss_temp = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        cond = batch.x  # initial position (condition)\n",
    "        x_0 = cond + torch.randn_like(batch.y[..., 0]).to(device)  # initial Gaussian noise\n",
    "\n",
    "        if symmetric_matching:  # find the closest target\n",
    "            mse, inds = MSELoss_allTargets(x_0, batch.y, batch.batch, return_indices=True)\n",
    "            inds = inds[batch.batch]\n",
    "            x_1 = torch.take_along_dim(batch.y, inds.reshape(-1, 1, 1), dim=-1).squeeze(-1)\n",
    "        else:  # use the first option as target\n",
    "            x_1 = batch.y[..., 0]  # final position (target)\n",
    "\n",
    "        n_batches = torch.max(batch.batch) + 1\n",
    "\n",
    "        t = torch.rand(n_batches, 1).to(device)[batch.batch]\n",
    "\n",
    "        x_t = (1 - t) * x_0 + t * x_1\n",
    "        dx_t = x_1 - x_0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(flow(t=t, x_t=x_t, batch=batch), dx_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_temp.append(loss.item())\n",
    "\n",
    "    if i == 200:\n",
    "        optimizer = torch.optim.Adam(flow.parameters(), 1e-5)\n",
    "    MSE_loss.append(np.mean(loss_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MSE_loss)\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "n_steps = 8\n",
    "\n",
    "fig, axes = plt.subplots(1, n_steps//2 + 1, figsize=(20, 4), sharex=True, sharey=True)\n",
    "\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1).to(device)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect('equal')\n",
    "    # ax.axline((0,0), (1,1), c='tab:red')\n",
    "    # ax.axline((0,0), (-1,1), c='tab:red')\n",
    "\n",
    "for j in range(10):  # 10 predictions per data point\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        cond = batch.x  # initial position (condition)\n",
    "        x = cond + torch.randn_like(cond).to(device)  # initial Gaussian noise\n",
    "\n",
    "        real = batch.y[..., 0].cpu().detach()*y_std+y_m  # final position (target)\n",
    "\n",
    "        pred = x.cpu().detach()*y_std+y_m\n",
    "\n",
    "        axes[0].scatter(real, pred, s=1, c='tab:blue')\n",
    "        axes[0].set_title(f't = {time_steps[0]:.2f}')\n",
    "        axes[0].legend()\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], batch=batch)\n",
    "\n",
    "            if i % 2 == 1:\n",
    "                pred = x.cpu().detach()*y_std+y_m\n",
    "                real = batch.y[..., 0].cpu().detach()*y_std+y_m  # final position (target)\n",
    "                axes[i//2 + 1].scatter(real, pred, s=1, c='tab:blue')\n",
    "                axes[i//2 + 1].set_title(f't = {time_steps[i + 1]:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bifurcation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Plot how ground truth bifurcates\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "flow.eval()\n",
    "for batch in test_loader:\n",
    "    for ind in range(100):\n",
    "        pos1 = (batch.x[[4*ind+0, 4*ind+2],0]*x_std+x_m).cpu().detach().numpy()\n",
    "        pos2a = (batch.y[[4*ind+0, 4*ind+2],0,0]*y_std+y_m).cpu().detach().numpy()\n",
    "        pos2b = (batch.y[[4*ind+1, 4*ind+3],0,0]*y_std+y_m).cpu().detach().numpy()\n",
    "\n",
    "        ax.scatter(*pos1,  c='tab:blue',   s=10, label='Initial')\n",
    "        ax.scatter(*pos2a, c='tab:orange', s=10, label='Final, node 0 & 2')\n",
    "        ax.scatter(*pos2b, c='tab:red',    s=10, label='Final, node 1 & 3')\n",
    "\n",
    "        ax.annotate('', xy=pos2a, xytext=pos1,\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=pos2b, xytext=pos1,\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:3], labels[:3])\n",
    "    ax.set_xlabel('Embedding node 0 and 1')\n",
    "    ax.set_ylabel('Embedding node 2 and 3')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('Ground truth bifurcation')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how result bifurcates (not conditioned on output)\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "flow.eval()\n",
    "for batch in test_loader:\n",
    "    batch = batch.clone().to(device=device)\n",
    "\n",
    "    cond = batch.x  # initial position (condition)\n",
    "    x = cond + torch.randn_like(cond).to(device)  # initial Gaussian noise\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], batch=batch)\n",
    "\n",
    "    pred = x\n",
    "\n",
    "    for ind in range(100):\n",
    "        pos1 = (batch.x[[4*ind+0, 4*ind+2]]*x_std+x_m).cpu().detach().numpy()\n",
    "        pos2a = (pred[[4*ind+0, 4*ind+2]]*y_std+y_m).cpu().detach().numpy()\n",
    "        pos2b = (pred[[4*ind+1, 4*ind+3]]*y_std+y_m).cpu().detach().numpy()\n",
    "\n",
    "        ax.scatter(*pos1,  c='tab:blue',   s=10, label='Initial')\n",
    "        ax.scatter(*pos2a, c='tab:orange', s=10, label='Final, node 0 & 2')\n",
    "        ax.scatter(*pos2b, c='tab:red',    s=10, label='Final, node 1 & 3')\n",
    "\n",
    "        ax.annotate('', xy=pos2a, xytext=pos1,\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=pos2b, xytext=pos1,\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:3], labels[:3])\n",
    "    ax.set_xlabel('Embedding node 0 and 1')\n",
    "    ax.set_ylabel('Embedding node 2 and 3')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('Predicted bifurcation')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Wasserstein distance\n",
    "And also the 'relative distance' (to do: think of better name?) distance to option 1/(distance to option 1 + distance to option 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = tg.loader.DataLoader(data_te, batch_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance_nd\n",
    "flow.eval()\n",
    "rel_dist = []\n",
    "for batch in test_loader:\n",
    "    batch = batch.clone().to(device)\n",
    "\n",
    "    preds = np.zeros((len(batch.x), 100))  # create 100 predictions per node\n",
    "\n",
    "    for i in range(100):  # make 100 predictions for each data point\n",
    "        batch = batch.clone().to(device=device)\n",
    "\n",
    "        cond = batch.x  # initial position (condition)\n",
    "        x = cond + torch.randn_like(cond).to(device)  # initial Gaussian noise\n",
    "\n",
    "        for j in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[j], t_end=time_steps[j + 1], batch=batch)\n",
    "\n",
    "        preds[..., i] = x.squeeze(-1).cpu().detach().numpy()*y_std+y_m\n",
    "\n",
    "\n",
    "    preds = preds.reshape(-1, 4, 100)\n",
    "    reals = batch.y.cpu().detach().numpy().reshape(-1, 4, 2)*y_std + y_m\n",
    "\n",
    "    print('preds.shape:', preds.shape)\n",
    "    print('reals.shape:', reals.shape)\n",
    "    wd = []\n",
    "    for pred, real in zip(preds, reals):  # iterate over all data points (as far as I know, this cannot be batched)\n",
    "        wd.append(wasserstein_distance_nd(pred.T, real.T))\n",
    "\n",
    "        diff = pred[..., np.newaxis] - real[..., np.newaxis, :]\n",
    "        dist = np.linalg.norm(diff, axis=0)\n",
    "        print(diff.shape)\n",
    "        print(dist.shape)\n",
    "        rel_dist_temp = dist[..., 0] / (dist[..., 0] + dist[..., 1])\n",
    "        print(rel_dist_temp.shape)\n",
    "        rel_dist.extend(rel_dist_temp.flatten().tolist())\n",
    "\n",
    "\n",
    "print(np.mean(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of rel_dist\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(rel_dist,\n",
    "         bins=np.linspace(0, 1, 40), density=True)\n",
    "plt.xlabel(r'$\\frac{\\text{Distance to option 1}}{\\text{Distance to option 1 + Distance to option 2}}$', fontsize=18)\n",
    "# change label font size x label\n",
    "plt.axvline(0.0, color='red', linestyle='--')\n",
    "plt.axvline(1.0, color='red', linestyle='--')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = tg.loader.DataLoader(data_te, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 32\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1).to(device)\n",
    "for batch in test_loader:\n",
    "    batch = batch.clone().to(device)\n",
    "    print('batch.x', batch.x.shape)\n",
    "    print('batch.y', batch.y.shape)\n",
    "\n",
    "    preds = np.zeros((4, 10000))  # create lots of predictions per node\n",
    "\n",
    "    for i in range(10000):  # make lots of predictions for each data point\n",
    "        batch = batch.clone().to(device=device)\n",
    "\n",
    "        cond = batch.x[:4]  # initial position (condition)\n",
    "        x = cond + torch.randn_like(cond).to(device)  # initial Gaussian noise\n",
    "\n",
    "        for j in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[j], t_end=time_steps[j + 1], batch=batch)\n",
    "\n",
    "        preds[..., i] = x.squeeze(-1).cpu().detach().numpy()*y_std+y_m\n",
    "\n",
    "    preds_1graph = preds.reshape(4, -1)\n",
    "    reals_1graph = batch.y[:4].cpu().detach().numpy().reshape(4, 2)*y_std + y_m\n",
    "\n",
    "    print('preds_1graph.shape:', preds_1graph.shape)\n",
    "    print('reals_1graph.shape:', reals_1graph.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = preds_1graph[..., np.newaxis] - reals_1graph[..., np.newaxis, :]\n",
    "dist = np.linalg.norm(diff, axis=0)\n",
    "print(diff.shape)\n",
    "print(dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist[:, 0], bins=np.linspace(-5, 25, 100), alpha=0.5, label='Distance to option 1', density=True)\n",
    "plt.hist(dist[:, 1], bins=np.linspace(-5, 25, 100), alpha=0.5, label='Distance to option 2', density=True)\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(dist[:, 0]/(dist[:,0] + dist[:, 1]),\n",
    "         bins=np.linspace(0, 1, 40), density=True)\n",
    "plt.xlabel(r'$\\frac{\\text{Distance to option 1}}{\\text{Distance to option 1 + Distance to option 2}}$', fontsize=18)\n",
    "# change label font size x label\n",
    "plt.axvline(0.0, color='red', linestyle='--')\n",
    "plt.axvline(1.0, color='red', linestyle='--')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dist[:, 0] < dist[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dist[:, 0] > dist[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dist[:, 0] == dist[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bools = (dist[:, 0] < dist[:, 1])+(dist[:, 0] > dist[:, 1])\n",
    "print(np.sum(bools))\n",
    "dist[bools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(dist).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dist[:, 0], dist[:, 1], s=1)\n",
    "plt.xlabel('Distance to option 1')\n",
    "plt.ylabel('Distance to option 2')\n",
    "plt.gca().set_aspect('equal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bifurc_env4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
