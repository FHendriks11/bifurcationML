{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset with bifurcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ThreeRoads_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# print info about all entries\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(key, value.size())\n",
    "    else:\n",
    "        print(key, value)\n",
    "\n",
    "data_tr = data['data_tr']\n",
    "data_te = data['data_te']\n",
    "x_m = data['x_m']\n",
    "y_m = data['y_m']\n",
    "x_std = data['x_std']\n",
    "y_std = data['y_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_tr, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_te, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_loss(logsig_i, mu_i, logsig_f=torch.tensor(0.0), mu_f=torch.tensor(0.0)):\n",
    "    temp = 2*(logsig_f-logsig_i) - 1 + torch.exp(logsig_i)**2/torch.exp(logsig_f)**2 + (mu_f - mu_i)**2/torch.exp(logsig_f)**2\n",
    "    temp = 0.5*torch.sum(temp, axis=-1)\n",
    "    return torch.mean(temp)\n",
    "\n",
    "def MSELoss_allTargets(pred, target, return_indices=False):\n",
    "    \"\"\"MSE loss applied on all possible targets, then taking the minimum per data point, i.e., using the closest target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : torch tensor, [N, f]\n",
    "        prediction per node, N = batch size, f = nr of predicted features\n",
    "    target : torch tensor, [N, f, a]\n",
    "        all possible targets, N = batch size, f = nr of predicted features, a = nr of possible alternatives\n",
    "    return_indices : bool, optional\n",
    "        whether to return the indices of the alternatives giving the minimum loss, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MSE : torch tensor, [1,]\n",
    "        MSE loss, using the closest alternative for each graph\n",
    "    indices : torch tensor, [N,]\n",
    "        index indicating which of the alternatives was closest\n",
    "    \"\"\"\n",
    "    # sum square error of both nodes per alternative (resulting shape: [N, a])\n",
    "    SE = torch.sum((pred.unsqueeze(-1) - target)**2, dim=1)\n",
    "    # take the minimum square error per graph\n",
    "    SE_min, inds = torch.min(SE, axis=-1)\n",
    "\n",
    "    # take mean over entire batch\n",
    "    MSE = torch.sum(SE_min)/(pred.numel())\n",
    "\n",
    "    if return_indices:\n",
    "        return MSE, inds\n",
    "    else:\n",
    "        return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')  # for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "#     print('cuda available')\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "#     print('cuda not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "As a base model, for the VAE, we use the same model as for the non-probabilistic model in ThreeRoads_non-probabilistic.ipynb, with one difference; the number of input and output features per node are now variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetModel(torch.nn.Module):\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super(SetModel, self).__init__()\n",
    "        self.mininet1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(size_in, 16),\n",
    "            # torch.nn.LeakyReLU(),\n",
    "            # torch.nn.Linear(16, 16),\n",
    "            # torch.nn.LeakyReLU(),\n",
    "            # torch.nn.Linear(16, 16),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "\n",
    "        self.mininet2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2*size_in, 16),\n",
    "            # torch.nn.LeakyReLU(),\n",
    "            # torch.nn.Linear(16, 16),\n",
    "            # torch.nn.LeakyReLU(),\n",
    "            # torch.nn.Linear(16, 16),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "\n",
    "        self.mininet3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32, 16),\n",
    "            # torch.nn.LeakyReLU(),\n",
    "            # torch.nn.Linear(16, 16),\n",
    "            # torch.nn.LeakyReLU(),\n",
    "            # torch.nn.Linear(16, 16),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(16, size_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [batch size, 2, size_in]\n",
    "        # output shape = [batch size, 2, size_out]\n",
    "        # use mini-net 1 on input 1 and input 2 separately\n",
    "        x1 = self.mininet1(x[:, 0])\n",
    "        x2 = self.mininet1(x[:, 1])\n",
    "\n",
    "        # use mini-net 2 on the the pair 1,2 and the pair 2,1 of inputs\n",
    "        x12 = self.mininet2(x.flatten(start_dim=1))\n",
    "        x21 = self.mininet2(x[:, [1, 0]].flatten(start_dim=1))\n",
    "\n",
    "        # make prediction for each node\n",
    "        x1 = self.mininet3(torch.cat([x1, x21], dim=1))\n",
    "        x2 = self.mininet3(torch.cat([x2, x12], dim=1))\n",
    "\n",
    "        # concatenate the two results\n",
    "        x = torch.stack([x1, x2], dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticSetModel(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setmodel1 = SetModel(1, embedding_dim)\n",
    "        self.setmodel2 = SetModel(2, embedding_dim)\n",
    "        self.mlp1 = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(embedding_dim, 16),\n",
    "                        torch.nn.LeakyReLU(),\n",
    "                        torch.nn.Linear(16, 2*latent_dim)\n",
    "                        )\n",
    "        self.mlp2 = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(embedding_dim*2, 16),\n",
    "                        torch.nn.LeakyReLU(),\n",
    "                        torch.nn.Linear(16, 2*latent_dim)\n",
    "                        )\n",
    "        self.setmodel3 = SetModel(embedding_dim+latent_dim, 1)\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def forward(self, x, y, cond_on_final=False):\n",
    "        # x shape: [batch size, 2]\n",
    "        # y shape: [batch size, 2]\n",
    "        bs = x.shape[0]\n",
    "\n",
    "        if x.ndim != 2 or x.shape[-1] != 2:\n",
    "            raise ValueError(f'x should have shape [batch size, 2], currently {x.shape}')\n",
    "        if cond_on_final:\n",
    "            if y.ndim != 2 or y.shape[-1] != 2:\n",
    "                raise ValueError(f'y should have shape [batch size, 2], currently {y.shape}')\n",
    "            if x.shape[0] != y.shape[0]:\n",
    "                raise ValueError(f'x and y should have the same batch size. Current shapes: x.shape={x.shape}, y.shape={y.shape}')\n",
    "\n",
    "        x = x.unsqueeze(dim=-1)  # new shapes: [batch size, 2, 1] (indicating 1 feature)\n",
    "        if cond_on_final:\n",
    "            y = y.unsqueeze(dim=-1)\n",
    "\n",
    "        # Apply set model to initial to create an embedding\n",
    "        x2 = self.setmodel1(x)  # shape [batch size, 2, 16]\n",
    "        # reshape to: [batch size*2, 16], so each node can be treated as a separate datapoint\n",
    "        x2 = x2.flatten(end_dim=1)\n",
    "        if cond_on_final:\n",
    "            x3 = self.setmodel2(torch.cat([x,y], dim=-1)) # shape [batch size, 2, 16]\n",
    "            x3 = x3.flatten(end_dim=1)\n",
    "\n",
    "        # Create logsig, mu from initial\n",
    "        logsig_mu_i = self.mlp1(x2).reshape(-1, 2, self.latent_dim)\n",
    "        # shape [batch size*2, 2 predictions (log sigma and mu), latent_dim]\n",
    "        logsig_i, mu_i = logsig_mu_i[:, 0], logsig_mu_i[:, 1]\n",
    "        # shape [batch size*2, latent_dim]\n",
    "        if cond_on_final:\n",
    "            # Create logsig, mu from initial and final\n",
    "            x4 = torch.cat((x2, x3), dim=-1)\n",
    "            logsig_mu_f = self.mlp2(x4).reshape(-1, 2, self.latent_dim)\n",
    "            logsig_f, mu_f = logsig_mu_f[:, 0], logsig_mu_f[:, 1]\n",
    "\n",
    "        # Sample (1 sample per node)\n",
    "        eps = torch.randn_like(logsig_i)\n",
    "        z_i = eps*torch.exp(logsig_i) + mu_i\n",
    "        z_i = z_i.reshape(-1, 2, self.latent_dim)\n",
    "        if cond_on_final:\n",
    "            eps = torch.randn_like(logsig_f)\n",
    "            z_f = eps*torch.exp(logsig_f) + mu_f\n",
    "            z_f = z_f.reshape(-1, 2, self.latent_dim)\n",
    "\n",
    "        x2 = x2.reshape(-1, 2, self.embedding_dim)\n",
    "        if cond_on_final:\n",
    "            x = torch.cat((x2, z_f), dim=-1)\n",
    "        else:\n",
    "            x = torch.cat((x2, z_i), dim=-1)\n",
    "\n",
    "        x = self.setmodel3(x)\n",
    "\n",
    "        if cond_on_final:\n",
    "            return logsig_i.reshape(-1, 2, self.latent_dim), mu_i.reshape(-1, 2, self.latent_dim), logsig_f.reshape(-1, 2, self.latent_dim), mu_f.reshape(-1, 2, self.latent_dim), x.squeeze(-1)\n",
    "        else:\n",
    "            return (x.squeeze(-1), )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use latent_dim=1 here to be able to visualize the latent space.\n",
    "# using a higher value might lead to better results (although from what I see, they seem to be bad anyways)\n",
    "model = ProbabilisticSetModel(embedding_dim=16, latent_dim=1).to(device)\n",
    "\n",
    "for batch in train_loader:\n",
    "    x = batch[..., 0].to(device)\n",
    "    y = batch[..., 1].to(device)\n",
    "    for asdf in model(x, y, cond_on_final=True):\n",
    "        print(asdf.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print('Total nr of parameters:', n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].to(device)\n",
    "    y = batch[..., 1].to(device)\n",
    "    pred = model(x, y)[-1]\n",
    "    print('Shapes:', pred.shape, y.shape)\n",
    "    y123 = batch[..., 1:].to(device)\n",
    "    print('Shape y123:', y123.shape)\n",
    "    test_loss, inds = MSELoss_allTargets(pred, y123, return_indices=True)\n",
    "    print('test RMSE', torch.sqrt(test_loss).item())\n",
    "\n",
    "    ground_truth = np.take_along_axis(y123.cpu().numpy(),\n",
    "                                    inds.reshape(-1, 1, 1).cpu().numpy(), axis=-1)\n",
    "    plt.scatter(ground_truth, pred.cpu().detach().numpy(), s=1)\n",
    "    # plt.gca().set_aspect('equal')\n",
    "    plt.xlabel('real')\n",
    "    plt.ylabel('predicted')\n",
    "    plt.title('Real vs predicted before training\\n(to check initialization of network)')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "losses = {\n",
    "            # on training data, while conditioning on output:\n",
    "            'MSE_train': [],\n",
    "            'KL_train': [],\n",
    "            'loss_train': [], # total loss\n",
    "\n",
    "            # on validation data, without conditioning on output:\n",
    "            'MSE_val': [],\n",
    "            'MSE_val_allTargets': [],  # MSE compared to closest target\n",
    "\n",
    "            # on validation data, but still conditioned on output:\n",
    "            'KL_val2': [],\n",
    "            'MSE_val2': []\n",
    "        }\n",
    "\n",
    "KL_increase_range = 50  # nr of epochs over which we increase the weight of the KL loss\n",
    "for epoch in range(500):\n",
    "# for epoch in range(50):\n",
    "    print(f'epoch {epoch}')\n",
    "\n",
    "    # ====================== 1) TRAIN ======================\n",
    "    KL_weight = np.clip(epoch/KL_increase_range, a_min=0.0, a_max=1.0)/2\n",
    "    print(' \\t KL_weight:', KL_weight)\n",
    "    losses_temp = {key: [] for key in losses}\n",
    "\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x = batch[..., 0].to(device)\n",
    "        y = batch[..., 1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(x, y, cond_on_final=True)\n",
    "        pred = out[-1]\n",
    "        if torch.isnan(pred).any():\n",
    "            raise ValueError('nan value in train prediction')\n",
    "\n",
    "        MSE_loss = torch.nn.MSELoss()(pred, y)\n",
    "        KL_loss1 = KL_loss(*out[:-1])\n",
    "\n",
    "        loss = (1.0-KL_weight)*MSE_loss + KL_weight*KL_loss1\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_temp['MSE_train'].append(MSE_loss.item())\n",
    "        losses_temp['KL_train'].append(KL_loss1.item())\n",
    "        losses_temp['loss_train'].append(loss.item())\n",
    "\n",
    "    for loss in ['MSE_train', 'KL_train', 'loss_train']:\n",
    "        losses[loss].append(np.mean(losses_temp[loss]))\n",
    "        print(f'\\t{loss:10} {losses[loss][-1]:8.4}')\n",
    "\n",
    "    # =============== 2) EVALUATE WITHOUT CONDITIONING ON OUTPUT ===============\n",
    "    # In evaluation mode, so not conditioned on output. Calculating KL loss is therefore not possible.\n",
    "    model.eval()\n",
    "    for batch in test_loader:\n",
    "        x = batch[..., 0].to(device)\n",
    "        y = batch[..., 1].to(device)\n",
    "        out = model(x, y, cond_on_final=False)\n",
    "        pred = out[-1]\n",
    "        if torch.isnan(pred).any():\n",
    "            raise ValueError('nan value in train prediction')\n",
    "\n",
    "        MSE_loss = torch.nn.MSELoss()(pred, y)\n",
    "        y123 = batch[..., 1:].to(device)\n",
    "        MSE_loss_alltarg, inds = MSELoss_allTargets(pred, y123, return_indices=True)\n",
    "\n",
    "        losses_temp['MSE_val'].append(MSE_loss.item())\n",
    "        losses_temp['MSE_val_allTargets'].append(MSE_loss_alltarg.item())\n",
    "\n",
    "    for loss in ['MSE_val', 'MSE_val_allTargets']:\n",
    "        losses[loss].append(np.mean(losses_temp[loss]))\n",
    "        print(f'\\t{loss:10} {losses[loss][-1]:8.4}')\n",
    "\n",
    "    # ================ 3) EVALUATE WITH CONDITIONING ON OUTPUT ================\n",
    "    model.eval()\n",
    "    for batch in test_loader:\n",
    "        x = batch[..., 0].to(device)\n",
    "        y = batch[..., 1].to(device)\n",
    "        out = model(x, y, cond_on_final=True)\n",
    "        pred = out[-1]\n",
    "        if torch.isnan(pred).any():\n",
    "            raise ValueError('nan value in train prediction')\n",
    "\n",
    "        MSE_loss = torch.nn.MSELoss()(pred, y)\n",
    "        KL_loss1 = KL_loss(*out[:-1])\n",
    "\n",
    "        losses_temp['MSE_val2'].append(MSE_loss.item())\n",
    "        losses_temp['KL_val2'].append(KL_loss1.item())\n",
    "\n",
    "    for loss in ['MSE_val2', 'KL_val2']:\n",
    "        losses[loss].append(np.mean(losses_temp[loss]))\n",
    "        print(f'\\t{loss:10} {losses[loss][-1]:8.4}')\n",
    "\n",
    "    # ======== Lowering learning rate, early stopping =========\n",
    "    # Stop training if both MSE and KL loss did not decrease enough on validation data\n",
    "    if (\n",
    "        epoch > KL_increase_range\n",
    "        and\n",
    "        (np.mean(losses[\"MSE_val_allTargets\"][-5:])\n",
    "             > 0.995*np.mean(losses[\"MSE_val_allTargets\"][-10:-5]))\n",
    "        and (np.mean(losses[\"KL_val2\"][-5:])\n",
    "             > 0.995*np.mean(losses[\"KL_val2\"][-10:-5]))\n",
    "    ):\n",
    "\n",
    "        print('======= !! Validation loss did not decrease enough =======')\n",
    "        print('Stopping training')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for key, value in losses.items():\n",
    "    plt.plot(value, label=key)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare input, output, predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    batch = batch[:6]\n",
    "    x = batch[..., 0].to(device)\n",
    "    y = batch[..., 1].to(device)\n",
    "    pred = model(x, y)[-1]\n",
    "\n",
    "    x = x.cpu().detach().numpy()*x_std + x_m\n",
    "    y123 = batch[..., 1:].cpu().detach().numpy()*y_std + y_m\n",
    "    pred = pred.cpu().detach().numpy()*y_std + y_m\n",
    "\n",
    "    # print input\n",
    "    print('============== INPUT ==============')\n",
    "    for asdf in x:\n",
    "        print(*asdf, sep=', ')\n",
    "\n",
    "    print('============== POSSIBLE OUTPUTS ==============')\n",
    "    for asdf in y123:  #.reshape(-1, 2, 3):\n",
    "        print(*asdf.T, sep=', ')\n",
    "\n",
    "    print('============== PREDICTIONS ==============')\n",
    "    for asdf in pred:\n",
    "        print(*asdf.T, sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows how 10 results for the first 10 data points. You can see that unlike the non-probabilistic model in ThreeRoads_non-probabilistic.ipynb, now if we run the model ten times on the same input, we get 10 different results. We also see that these results form clusters around the three possible outputs, which is what we want, but we also see that this clusters are not very sharp; there are quite some results that are inbetween the possible options. This not what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds_all = []\n",
    "for batch in test_loader:\n",
    "\n",
    "    for _ in range(50): # create 50 predictions for each of the 10 first data points\n",
    "        x = batch[..., 0].to(device)\n",
    "        y1 = batch[..., 1].to(device)\n",
    "        out = model(x, y1, cond_on_final=False)\n",
    "        y_pred = out[-1].cpu().detach().numpy()*y_std + y_m\n",
    "        x = x.cpu().detach().numpy()*x_std + x_m\n",
    "\n",
    "        preds_all.extend(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bifurcations in the first 10 cases\n",
    "fig, ax = plt.subplots(figsize=(3,5), dpi=300)\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].numpy()*x_std + x_m\n",
    "    y1 = batch[..., 1].numpy()*y_std + y_m\n",
    "    y2 = batch[..., 2].numpy()*y_std + y_m\n",
    "    y3 = batch[..., 3].numpy()*y_std + y_m\n",
    "\n",
    "    for i in range(10): # iterate over 10 first data points\n",
    "        ax.scatter(*x[i], c='tab:blue', s=50, label='_'*i + 'Initial')\n",
    "        ax.scatter(*y1[i], c='tab:orange', s=10, label='_'*i + 'Option 1')\n",
    "        ax.scatter(*y2[i], c='tab:green', s=10, label='_'*i + 'Option 2')\n",
    "        ax.scatter(*y3[i], c='tab:red', s=10, label='_'*i + 'Option 3')\n",
    "\n",
    "        ax.annotate('', xy=y1[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y2[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y3[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "ax.scatter(preds_all[:, 0], preds_all[:, 1], c='magenta', s=50, marker='x', label='Prediction', alpha=0.3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles[:5], labels[:5])\n",
    "ax.set_xlabel('Person 1')\n",
    "ax.set_ylabel('Person 2')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows what happens when you condition on one of the target outputs, which is what we do during training. It shows that most of the time, there is a cluster around option 1, which is the one that is being conditioned upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bifurcations in the first 10 cases\n",
    "fig, ax = plt.subplots(figsize=(5,8))\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].numpy()*x_std + x_m\n",
    "    y1 = batch[..., 1].numpy()*y_std + y_m\n",
    "    y2 = batch[..., 2].numpy()*y_std + y_m\n",
    "    y3 = batch[..., 3].numpy()*y_std + y_m\n",
    "\n",
    "    for i in range(10):\n",
    "        ax.scatter(*x[i], c='tab:blue', s=50, label='_'*i + 'Initial')\n",
    "        ax.scatter(*y1[i], c='tab:orange', s=10, label='_'*i + 'Option 1')\n",
    "        ax.scatter(*y2[i], c='tab:green', s=10, label='_'*i + 'Option 2')\n",
    "        ax.scatter(*y3[i], c='tab:red', s=10, label='_'*i + 'Option 3')\n",
    "\n",
    "        ax.annotate('', xy=y1[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y2[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y3[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "\n",
    "    for _ in range(20):\n",
    "        x = batch[..., 0].to(device)\n",
    "        y1 = batch[..., 1].to(device)\n",
    "        out = model(x, y1, cond_on_final=True)\n",
    "        y_pred = out[-1].cpu().detach().numpy()*y_std + y_m\n",
    "        x = x.cpu().detach().numpy()*x_std + x_m\n",
    "\n",
    "        for i in range(10):\n",
    "\n",
    "            ax.scatter(*y_pred[i], c='magenta', s=50, marker='x', label='Prediction', alpha=0.3)\n",
    "\n",
    "            # ax.annotate('', xy=y_pred[i], xytext=x[i],\n",
    "            #             arrowprops=dict(arrowstyle='->', facecolor='gray', edgecolor='magenta', alpha=0.3),\n",
    "            #                 )\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles[:5], labels[:5])\n",
    "ax.set_xlabel('Node 1')\n",
    "ax.set_ylabel('Node 2')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot real vs predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots below show the real value per node versus the value predicted by the model. However, if we compare the predicted value simply with option 1 (the values that would be trained on), then the performance looks bad if the model happens to predict one of the other two valid solutions, even though this is actually exactly the behavior we want. Therefore, we pick the closest valid output option and use that as our ground truth.\n",
    "\n",
    "For the second plot we again condition on option 1, just as we do during training.\n",
    "It looks like the performance in both cases is similar, which is good news since it means that the model does not rely on the given output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].to(device)\n",
    "    y123 = batch[..., 1:].to(device)\n",
    "    batch = batch.clone()\n",
    "    batch.to(device=device)\n",
    "    pred = model(x, None)[-1]\n",
    "\n",
    "    _, inds = MSELoss_allTargets(pred, y123, return_indices=True)\n",
    "\n",
    "ground_truth = np.take_along_axis(y123.cpu().detach().numpy(),\n",
    "                                  inds.cpu().numpy().reshape(-1,1,1), axis=-1)\n",
    "plt.scatter(ground_truth*y_std+y_m, pred.cpu().detach().numpy()*y_std+y_m, s=1)\n",
    "plt.axline([0,0], [1,1], c='tab:orange')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('real')\n",
    "plt.ylabel('predicted')\n",
    "plt.title('Real (best match) vs predicted')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].to(device)\n",
    "    y = batch[..., 1].to(device)\n",
    "    batch = batch.clone()\n",
    "    batch.to(device=device)\n",
    "    pred = model(x, y, cond_on_final=True)[-1]\n",
    "\n",
    "y = y.cpu().detach().numpy()\n",
    "plt.scatter(y*y_std+y_m, pred.cpu().detach().numpy()*y_std+y_m, s=1)\n",
    "plt.axline([0,0], [1,1], c='tab:orange')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('real')\n",
    "plt.ylabel('predicted')\n",
    "plt.title('Real vs predicted, conditioned on output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contourplot of latent space\n",
    "Needs a latent_dim of 1, so there is one latent dimension per node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model.latent_dim == 1:\n",
    "    raise ValueError('Cannot visualize latent space if latent_dim is not 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "N = 300\n",
    "v1, v2 = -40.0, 40.0\n",
    "d = v2 - v1\n",
    "options = [[v1-d/2, v2-d/2], [v1-d/2, v2+d/2], [v1+d/2, v2+d/2]]\n",
    "options = np.tile(np.array(options).T, reps=(N, 1, 1))\n",
    "alpha = 1.0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_new = (torch.FloatTensor([v1,v2]*N).reshape(-1, 2, 1)-x_m)/x_std\n",
    "    x_new = x_new.to(device)\n",
    "    y = (torch.from_numpy(options).float().reshape(-1, 2, 3)-y_m)/y_std\n",
    "    y = y.to(device)\n",
    "\n",
    "    # apply first part of model to get latent space mu and sigma\n",
    "    x2 = model.setmodel1(x_new)\n",
    "    x2 = x2.flatten(end_dim=1)\n",
    "    logsig_mu_i = model.mlp1(x2).reshape(-1, 2, model.latent_dim)\n",
    "    logsig_i, mu_i = logsig_mu_i[:, 0], logsig_mu_i[:, 1]\n",
    "    logsig_f = []\n",
    "    mu_f = []\n",
    "    for i in range(3):\n",
    "        y_temp = y[..., [i]]\n",
    "        asdf = torch.cat([x_new,y_temp], dim=-1)\n",
    "        x3 = model.setmodel2(asdf)\n",
    "        x3 = x3.flatten(end_dim=1)\n",
    "        x4 = torch.cat((x2, x3), dim=-1)\n",
    "        logsig_mu_f = model.mlp2(x4).reshape(-1, 2, model.latent_dim)\n",
    "        logsig_f.append(logsig_mu_f[:, 0])\n",
    "        mu_f.append(logsig_mu_f[:, 1])\n",
    "\n",
    "    # sample\n",
    "    eps = torch.randn_like(logsig_i)\n",
    "    z_i = eps*torch.exp(logsig_i) + mu_i\n",
    "    z_f = []\n",
    "    for i in range(3):\n",
    "        eps = torch.randn_like(logsig_f[i])\n",
    "        temp = eps*torch.exp(logsig_f[i]) + mu_f[i]\n",
    "        temp = temp.reshape(-1, 2, model.latent_dim)\n",
    "        z_f.append(temp)\n",
    "\n",
    "    # turn sample into prediction\n",
    "    x2 = x2.reshape(-1, 2, model.embedding_dim)\n",
    "    x_new = torch.cat((x2, z_i.reshape(-1, 2, model.latent_dim)), dim=-1)\n",
    "    x_new = model.setmodel3(x_new)\n",
    "    pred = x_new.squeeze(-1).cpu().detach().numpy()*y_std + y_m\n",
    "    preds = []\n",
    "    for i in range(3):\n",
    "        x_new = torch.cat((x2, z_f[i]), dim=-1)\n",
    "        x_new = model.setmodel3(x_new)\n",
    "        preds.append(x_new.squeeze(-1).cpu().detach().numpy()*y_std + y_m)\n",
    "\n",
    "    mu_i = mu_i.reshape(-1, 2)\n",
    "    logsig_i = logsig_i.reshape(-1, 2)\n",
    "    z_i = z_i.reshape(-1, 2)\n",
    "    for i in range(3):\n",
    "        logsig_f[i] = logsig_f[i].reshape(-1, 2)\n",
    "        mu_f[i] = mu_f[i].reshape(-1, 2)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    # draw ellipse patch centered at mu_i with axes given by np.exp(logsig_i)\n",
    "    ellipse = mpatch.Ellipse(mu_i[0],\n",
    "                            width=2*np.exp(logsig_i[0,0].cpu().detach().numpy()),\n",
    "                            height=2*np.exp(logsig_i[0,1].cpu().detach().numpy()),\n",
    "                            fc='None', edgecolor='black')\n",
    "    plt.gca().add_patch(ellipse)\n",
    "    colors = ['tab:orange', 'tab:blue', 'tab:red']\n",
    "    for i in range(3):\n",
    "        ellipse = mpatch.Ellipse(mu_f[i][0],\n",
    "                                width=2*np.exp(logsig_f[i][0,0].cpu().detach().numpy()),\n",
    "                                height=2*np.exp(logsig_f[i][0,1].cpu().detach().numpy()),\n",
    "                                fc='None', edgecolor=colors[i])\n",
    "        plt.gca().add_patch(ellipse)\n",
    "\n",
    "    # plot samples\n",
    "    plt.scatter(z_i[:, 0].cpu().detach().numpy(), z_i[:, 1].cpu().detach().numpy(), s=1, label='latent space samples', color='black', alpha=alpha)\n",
    "    for i in range(3):\n",
    "        plt.scatter(z_f[i][:, 0].cpu().detach().numpy(), z_f[i][:, 1].cpu().detach().numpy(), s=1, label=f'latent space samples, cond. on option {i}', alpha=alpha, color=colors[i])\n",
    "\n",
    "    # plot means\n",
    "    plt.scatter(mu_i[:, 0].cpu().detach().numpy(), mu_i[:, 1].cpu().detach().numpy(), s=50, label='latent space means', c='black', marker='x')\n",
    "    for i in range(3):\n",
    "        plt.scatter(mu_f[i][:, 0].cpu().detach().numpy(), mu_f[i][:, 1].cpu().detach().numpy(), s=50, marker='x', label=f'latent space means, cond. on option {i}', color=colors[i])\n",
    "\n",
    "    # contourplot of z1, z2 vs pred\n",
    "    minz = min(mu_i[0,0].cpu().item() - 5*np.exp(logsig_i[0,0].cpu().item()),\n",
    "               mu_i[0,1].cpu().item() - 5*np.exp(logsig_i[0,1].cpu().item())\n",
    "    )\n",
    "    maxz = max(mu_i[0,0].cpu().item() + 5*np.exp(logsig_i[0,0].cpu().item()),\n",
    "               mu_i[0,1].cpu().item() + 5*np.exp(logsig_i[0,1].cpu().item())\n",
    "    )\n",
    "    plt.gca().set_xlim([minz,  maxz])\n",
    "    plt.gca().set_ylim([minz, maxz])\n",
    "\n",
    "    Z1, Z2 = np.meshgrid(\n",
    "        np.linspace(minz, maxz, 100),\n",
    "        np.linspace(minz, maxz, 100))\n",
    "    Z1 = torch.tensor(Z1).float().to(device).reshape(-1, 1, 1)\n",
    "    Z2 = torch.tensor(Z2).float().to(device).reshape(-1, 1, 1)\n",
    "    Z = torch.cat((Z1, Z2), dim=1)\n",
    "\n",
    "    # turn sample into prediction\n",
    "    x_new = (torch.FloatTensor([v1,v2]*100*100).reshape(-1, 2, 1)-x_m)/x_std\n",
    "    x_new = x_new.to(device)\n",
    "    x2 = model.setmodel1(x_new)\n",
    "    x2 = x2.reshape(-1, 2, model.embedding_dim)\n",
    "    x_new = torch.cat((x2, Z), dim=-1)\n",
    "    x_new = model.setmodel3(x_new)\n",
    "    pred_grid = x_new.squeeze(-1)\n",
    "    _, inds = MSELoss_allTargets(pred_grid, y[[0]], return_indices=True)\n",
    "\n",
    "\n",
    "    cnt = plt.contourf(Z1.cpu().detach().numpy().reshape(100, 100),\n",
    "                Z2.cpu().detach().numpy().reshape(100, 100),\n",
    "                inds.cpu().numpy().reshape(100, 100),\n",
    "                levels=[-0.5, 0.5, 1.5, 2.5],\n",
    "                cmap='viridis', alpha=0.5, zorder=-10)\n",
    "    plt.colorbar(label='Closest option to prediction',\n",
    "        ticks=[0, 1, 2])\n",
    "    plt.legend()\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel('$z_1$')\n",
    "    plt.ylabel('$z_2$')\n",
    "    plt.gca().set_title('VAE latent space. Ellipses indicate standard deviation.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resulting predictions for the samples shown in the latent space plot above\n",
    "fig, ax = plt.subplots(figsize=(5,8))\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "x = [v1, v2]\n",
    "y1 = options[0,:,0]\n",
    "y2 = options[0,:,1]\n",
    "y3 = options[0,:,2]\n",
    "\n",
    "ax.scatter(*x, c='tab:green', s=50, label='Initial')\n",
    "\n",
    "for i, y_temp in enumerate([y1, y2, y3]):\n",
    "    ax.scatter(*y_temp, c=colors[i], s=10, label=f'Option {i+1}')\n",
    "# ax.scatter(*y1, c='tab:orange', s=10, label='Option 1')\n",
    "# ax.scatter(*y2, c='tab:green', s=10, label='Option 2')\n",
    "# ax.scatter(*y3, c='tab:red', s=10, label='Option 3')\n",
    "\n",
    "ax.annotate('', xy=y1, xytext=x,\n",
    "            arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "            )\n",
    "ax.annotate('', xy=y2, xytext=x,\n",
    "            arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "            )\n",
    "ax.annotate('', xy=y3, xytext=x,\n",
    "            arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "            )\n",
    "\n",
    "for i, pred_temp in enumerate(preds):\n",
    "    ax.scatter(*pred_temp.T, s=50, marker='x', label=f'Prediction, conditioned on option {i+1}', alpha=0.2, color=colors[i])\n",
    "\n",
    "ax.scatter(*pred.T, s=50, marker='x', label='Prediction, no conditioning', alpha=0.2, color='black')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles, labels)\n",
    "ax.set_xlabel('Node 1')\n",
    "ax.set_ylabel('Node 2')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance_nd\n",
    "\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    batch = batch.clone().to(device)\n",
    "\n",
    "    preds = np.zeros((len(batch), 2, 100))  # create 100 predictions per data point\n",
    "\n",
    "    for i in range(100):  # make 100 predictions for each data point\n",
    "        pred = model(batch[..., 0], batch[..., 1], cond_on_final=False)[-1]\n",
    "        preds[..., i] = pred.cpu().detach().numpy()*y_std+y_m\n",
    "\n",
    "\n",
    "    reals = batch[..., 1:].cpu().detach().numpy()*y_std + y_m\n",
    "\n",
    "    print(preds.shape)\n",
    "    print(reals.shape)\n",
    "\n",
    "    wd = []\n",
    "    for pred, real in zip(preds, reals):  # iterate over all data points (as far as I know, this cannot be batched)\n",
    "        wd.append(wasserstein_distance_nd(pred.T, real.T))\n",
    "\n",
    "print('Mean Wasserstein distance between real and predicted:', np.mean(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bifurc_env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
