{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ThreeRoads_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# print info about all entries\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(key, value.size())\n",
    "    else:\n",
    "        print(key, value)\n",
    "\n",
    "data_tr = data['data_tr']\n",
    "data_te = data['data_te']\n",
    "x_m = data['x_m']\n",
    "y_m = data['y_m']\n",
    "x_std = data['x_std']\n",
    "y_std = data['y_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_tr, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_te, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('cuda available')\n",
    "    # mlflow.log_param('device', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('cuda not available')\n",
    "    # mlflow.log_param('device', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(nn.Module):\n",
    "    def __init__(self, dim: int = 1, cond: int = 1, h: int = 16):\n",
    "        # dim: dimension of data sample\n",
    "        # cond: dimension of the thing we're conditioning on (the bet in this case)\n",
    "        # h: hidden layer size\n",
    "        super().__init__()\n",
    "        super(Flow, self).__init__()\n",
    "        self.mininet1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h)\n",
    "        )\n",
    "\n",
    "        self.mininet2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h)\n",
    "        )\n",
    "\n",
    "        self.mininet3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2*h, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, h),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t: Tensor, x_t: Tensor, cond: Tensor) -> Tensor:\n",
    "        # cond = initial position: shape (batch_size, 2)\n",
    "        # x_t = current position: shape (batch_size, 2)\n",
    "        # t = current time: shape (batch_size, 1)\n",
    "\n",
    "        x1 = torch.cat((t, x_t[:, 0:1], cond[:, 0:1]), 1)  # shape [batch size, 3]\n",
    "        x2 = torch.cat((t, x_t[:, 1:2], cond[:, 1:2]), 1)\n",
    "\n",
    "        # use mini-net 1 on input 1 and input 2 separately\n",
    "        x1 = self.mininet1(x1)  # shape [batch size, h]\n",
    "        x2 = self.mininet1(x2)  # shape [batch size, h]\n",
    "\n",
    "        # print(t.shape, x_t.shape, cond.shape)\n",
    "\n",
    "        # use mini-net 2 on the the pair 1,2 and the pair 2,1 of inputs\n",
    "        x12 = torch.cat((t, x_t, cond), 1)\n",
    "        x21 = torch.cat((t, x_t[:, [1, 0]], cond[:, [1, 0]]), 1)\n",
    "        x12 = self.mininet2(x12)  # shape [batch size, h]\n",
    "        x21 = self.mininet2(x21)  # shape [batch size, h]\n",
    "\n",
    "        # make prediction for each node\n",
    "        x1 = self.mininet3(torch.cat([x1, x21], dim=1))\n",
    "        x2 = self.mininet3(torch.cat([x2, x12], dim=1))\n",
    "\n",
    "        # concatenate the two results\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        return x  # shape [batch size, 2]\n",
    "\n",
    "    def step(self, x_t: Tensor, t_start: Tensor, t_end: Tensor, cond: Tensor) -> Tensor:\n",
    "        # t: float, current time\n",
    "        # t_end: float, end time\n",
    "        # x_t: shape [batch size, 2], current position\n",
    "        # cond: shape [batch size, 2], initial position\n",
    "\n",
    "        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1)\n",
    "\n",
    "        # print('x_t.shape', x_t.shape)\n",
    "        # print('t_start.shape', t_start.shape)\n",
    "        # print('t_end.shape', t_end.shape)\n",
    "        # print('cond.shape', cond.shape)\n",
    "\n",
    "\n",
    "        return (x_t + (t_end - t_start)\n",
    "                * self(\n",
    "                    t=t_start + (t_end - t_start) / 2,\n",
    "                    x_t= x_t + self(x_t=x_t, t=t_start, cond=cond) * (t_end - t_start) / 2,\n",
    "                    cond=cond\n",
    "                       )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Flow().to(device)\n",
    "print(flow)\n",
    "\n",
    "n_params = sum(p.numel() for p in flow.parameters())\n",
    "print('Total nr of parameters:', n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "MSE_loss = []\n",
    "for i in range(1000):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    loss_temp = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        x_1 = batch[..., 1]  # final position (target)\n",
    "        cond = batch[..., 0]  # initial position (condition)\n",
    "        x_0 = cond + 0.5*torch.randn_like(x_1).to(device)  # initial Gaussian noise\n",
    "        t = torch.rand(len(x_1), 1).to(device)\n",
    "\n",
    "        x_t = (1 - t) * x_0 + t * x_1\n",
    "        dx_t = x_1 - x_0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(flow(t=t, x_t=x_t, cond=cond), dx_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_temp.append(loss.item())\n",
    "\n",
    "    if i == 200:\n",
    "        optimizer = torch.optim.Adam(flow.parameters(), 1e-5)\n",
    "    MSE_loss.append(np.mean(loss_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MSE_loss)\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "n_steps = 8\n",
    "\n",
    "fig, axes = plt.subplots(1, n_steps//2 + 1, figsize=(20, 4), sharex=True, sharey=True)\n",
    "\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1).to(device)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect('equal')\n",
    "    # ax.axline((0,0), (1,1), c='tab:red')\n",
    "    # ax.axline((0,0), (-1,1), c='tab:red')\n",
    "\n",
    "for j in range(10):  # 10 predictions per data point\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        cond = batch[..., 0]  # conditioning on the bet\n",
    "        x = cond + 0.5*torch.randn_like(batch[..., 1]).to(device)  # initial gaussian noise\n",
    "        bet = cond.cpu()*x_std+x_m\n",
    "        pred = x.cpu().detach()*y_std+y_m\n",
    "        real = batch[..., 1].cpu()*y_std+y_m\n",
    "        axes[0].scatter(bet, pred, s=1, label='_'*j+'predicted', c='tab:orange')\n",
    "        axes[0].scatter(bet, real, s=1, label='_'*j+'real', c='tab:blue')\n",
    "        axes[0].set_title(f't = {time_steps[0]:.2f}')\n",
    "        axes[0].legend()\n",
    "        axes[0].set_xlim(-100.0, 100.0)\n",
    "        axes[0].set_ylim(-100.0, 100.0)\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], cond=cond)\n",
    "\n",
    "            if i % 2 == 1:\n",
    "                bet = cond.cpu()*x_std+x_m\n",
    "                pred = x.cpu().detach()*y_std+y_m\n",
    "                real = batch[..., 1].cpu()*y_std+y_m\n",
    "                axes[i//2 + 1].scatter(bet, real, s=1, label='real', c='tab:blue')\n",
    "                axes[i//2 + 1].scatter(bet, pred, s=1, label='predicted', c='tab:orange')\n",
    "                                    # , s=1, c='tab:blue', alpha=0.5)\n",
    "                axes[i//2 + 1].set_title(f't = {time_steps[i + 1]:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 64\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1).to(device)\n",
    "\n",
    "flow.eval()\n",
    "preds_all = []\n",
    "for batch in test_loader:\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    for _ in range(50):\n",
    "\n",
    "        x = batch[..., 0].to(device)\n",
    "        x = cond + 0.5*torch.randn_like(batch[..., 1]).to(device)  # initial gaussian noise\n",
    "        cond = batch[..., 0]  # conditioning on the bet\n",
    "        bet = cond.cpu()*x_std+x_m\n",
    "        pred = x.cpu().detach()*y_std+y_m\n",
    "        real = batch[..., 1].cpu()*y_std+y_m\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], cond=cond)\n",
    "\n",
    "        y_pred = x.cpu().detach().numpy()*y_std + y_m\n",
    "        preds_all.extend(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bifurcations in the first 10 cases\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(figsize=(3,5), dpi=300)\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].numpy()*x_std + x_m\n",
    "    y1 = batch[..., 1].numpy()*y_std + y_m\n",
    "    y2 = batch[..., 2].numpy()*y_std + y_m\n",
    "    y3 = batch[..., 3].numpy()*y_std + y_m\n",
    "\n",
    "    for i in range(10): # iterate over 10 first data points\n",
    "        ax.scatter(*x[i], c='tab:blue', s=50, label='_'*i + 'Initial')\n",
    "        ax.scatter(*y1[i], c='tab:orange', s=10, label='_'*i + 'Option 1')\n",
    "        ax.scatter(*y2[i], c='tab:green', s=10, label='_'*i + 'Option 2')\n",
    "        ax.scatter(*y3[i], c='tab:red', s=10, label='_'*i + 'Option 3')\n",
    "\n",
    "        ax.annotate('', xy=y1[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y2[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y3[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "ax.scatter(preds_all[:, 0], preds_all[:, 1], c='magenta', s=50, marker='x', label='Prediction', alpha=0.3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles[:5], labels[:5])\n",
    "ax.set_xlabel('Person 1')\n",
    "ax.set_ylabel('Person 2')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance_nd\n",
    "\n",
    "flow.eval()\n",
    "for batch in test_loader:\n",
    "    batch = batch.clone().to(device)\n",
    "\n",
    "    preds = np.zeros((len(batch), 2, 100))  # create 100 predictions per data point\n",
    "\n",
    "    for i in range(100):  # make 100 predictions for each data point\n",
    "\n",
    "        x = batch[..., 0].to(device)\n",
    "        x = cond + 0.5*torch.randn_like(batch[..., 1]).to(device)  # initial gaussian noise\n",
    "        cond = batch[..., 0]  # conditioning on the bet\n",
    "        bet = cond.cpu()*x_std+x_m\n",
    "        pred = x.cpu().detach()*y_std+y_m\n",
    "        real = batch[..., 1].cpu()*y_std+y_m\n",
    "\n",
    "        for j in range(n_steps):\n",
    "            x = flow.step(x_t=x, t_start=time_steps[j], t_end=time_steps[j + 1], cond=cond)\n",
    "\n",
    "        preds[..., i] = x.cpu().detach().numpy()*y_std+y_m\n",
    "\n",
    "\n",
    "    reals = batch[..., 1:].cpu().detach().numpy()*y_std + y_m\n",
    "\n",
    "    print(preds.shape)\n",
    "    print(reals.shape)\n",
    "\n",
    "    wd = []\n",
    "    for pred, real in zip(preds, reals):  # iterate over all data points (as far as I know, this cannot be batched)\n",
    "        wd.append(wasserstein_distance_nd(pred.T, real.T))\n",
    "\n",
    "print('Mean Wasserstein distance between real and predicted:', np.mean(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bifurc_env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
