{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try a conventional, non-probabilistic approach on the Three Roads Problem, and show how it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ThreeRoads_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# print info about all entries\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(key, value.size())\n",
    "    else:\n",
    "        print(key, value)\n",
    "\n",
    "data_tr = data['data_tr']\n",
    "data_te = data['data_te']\n",
    "x_m = data['x_m']\n",
    "y_m = data['y_m']\n",
    "x_std = data['x_std']\n",
    "y_std = data['y_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_tr, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_te, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('cuda available')\n",
    "    # mlflow.log_param('device', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('cuda not available')\n",
    "    # mlflow.log_param('device', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SetModel, self).__init__()\n",
    "        self.mininet1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10)\n",
    "        )\n",
    "\n",
    "        self.mininet2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10)\n",
    "        )\n",
    "\n",
    "        self.mininet3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(20, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # use mini-net 1 on input 1 and input 2 separately\n",
    "        x1 = self.mininet1(x[:, 0:1])\n",
    "        x2 = self.mininet1(x[:, 1:2])\n",
    "\n",
    "        # use mini-net 2 on the the pair 1,2 and the pair 2,1 of inputs\n",
    "        x12 = self.mininet2(x)\n",
    "        x21 = self.mininet2(x[:, [1, 0]])\n",
    "\n",
    "        # make prediction for each node\n",
    "        x1 = self.mininet3(torch.cat([x1, x21], dim=1))\n",
    "        x2 = self.mininet3(torch.cat([x2, x12], dim=1))\n",
    "\n",
    "        # concatenate the two results\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SetModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test permutation equivariance\n",
    "for batch in train_loader:\n",
    "    x = batch[..., 0].to(device)\n",
    "    y = batch[..., 1].to(device)\n",
    "    y_pred = model(x)\n",
    "    print(y_pred[:10])\n",
    "\n",
    "    # flip inputs (the two nodes swap values)\n",
    "    x = x[:, [1,0]]\n",
    "    y = y[:, [1,0]]\n",
    "    y_pred = model(x)\n",
    "    print(y_pred[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "MSE_train = []\n",
    "MSE_val = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "\n",
    "    # ====================== 1) TRAIN ======================\n",
    "    model.train()\n",
    "    print(f'epoch {epoch}', end=' ')\n",
    "    MSE_train_temp = []\n",
    "    for batch in train_loader:\n",
    "        x = batch[..., 0].to(device)\n",
    "        y = batch[..., 1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        if torch.isnan(pred).any():\n",
    "            raise ValueError('nan value in train prediction')\n",
    "\n",
    "        MSE_loss = torch.nn.MSELoss()(pred, y)\n",
    "\n",
    "        MSE_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        MSE_train_temp.append(MSE_loss.item())\n",
    "\n",
    "    MSE_train.append(np.mean(MSE_train_temp))\n",
    "    print(f'train {MSE_train[-1]:8.4}, ', end='')\n",
    "\n",
    "    # ====================== 2) EVALUATE ======================\n",
    "    model.eval()\n",
    "    MSE_val_temp = []\n",
    "    for batch in test_loader:\n",
    "        x = batch[..., 0].to(device)\n",
    "        y = batch[..., 1].to(device)\n",
    "        pred = model(x)\n",
    "\n",
    "        if torch.isnan(pred).any():\n",
    "            raise ValueError('nan value in val prediction')\n",
    "\n",
    "        MSE_loss = torch.nn.MSELoss()(pred, y)\n",
    "        MSE_val_temp.append(MSE_loss.item())\n",
    "\n",
    "    MSE_val.append(np.mean(MSE_val_temp))\n",
    "    print(f'val {MSE_val_temp[-1]:8.4}')\n",
    "\n",
    "    # ======== Early stopping =========\n",
    "    if np.mean(MSE_val[-5:]) > 0.995*np.mean(MSE_val[-10:-5]):\n",
    "        print('======= !! Validation loss did not decrease enough =======')\n",
    "        print('Stopping training')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MSE_train, label='training')\n",
    "plt.plot(MSE_val, label='validation')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training curve above shows that in the beginning, the network learns to make a prediction in the right range, but after that it does not improve any more.\n",
    "Below, we plot the predicted outputs together with the 3 possible outputs to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds_all = []\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].to(device)\n",
    "    y_pred = model(x).cpu().detach().numpy()*y_std + y_m\n",
    "\n",
    "    preds_all.extend(y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bifurcations in the first 10 cases\n",
    "fig, ax = plt.subplots(figsize=(3,5), dpi=300)\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    x = batch[..., 0].to(device)\n",
    "    y1 = batch[..., 1].numpy()*y_std + y_m\n",
    "    y2 = batch[..., 2].numpy()*y_std + y_m\n",
    "    y3 = batch[..., 3].numpy()*y_std + y_m\n",
    "    x = x.cpu().detach().numpy()*x_std + x_m\n",
    "\n",
    "    for i in range(10):\n",
    "        ax.scatter(*x[i], c='tab:blue', s=50, label='_'*i + 'Initial')\n",
    "        ax.scatter(*y1[i], c='tab:orange', s=10, label='_'*i + 'Option 1')\n",
    "        ax.scatter(*y2[i], c='tab:green', s=10, label='_'*i + 'Option 2')\n",
    "        ax.scatter(*y3[i], c='tab:red', s=10, label='_'*i + 'Option 3')\n",
    "        # ax.scatter(*y_pred[i], c='magenta', s=50, marker='x', label='Prediction')\n",
    "\n",
    "        ax.annotate('', xy=y1[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y2[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        ax.annotate('', xy=y3[i], xytext=x[i],\n",
    "                    arrowprops=dict(arrowstyle='->', facecolor='black'),\n",
    "                    )\n",
    "        # ax.annotate('', xy=y_pred[i], xytext=x[i],\n",
    "        #             arrowprops=dict(arrowstyle='->', facecolor='gray', edgecolor='magenta'),\n",
    "        #             )\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "ax.scatter(preds_all[:, 0], preds_all[:, 1], c='magenta', s=50, marker='x', label='Prediction')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles[:5], labels[:5])\n",
    "ax.set_xlabel('Person 1')\n",
    "ax.set_ylabel('Person 2')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that each time the model predicts approximately the average of the 3 options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance_nd\n",
    "\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    batch = batch.clone().to(device)\n",
    "\n",
    "    preds = np.zeros((len(batch), 2, 100))  # create 100 predictions per data point\n",
    "\n",
    "    for i in range(100):  # make 100 predictions for each data point\n",
    "        pred = model(batch[..., 0])\n",
    "        preds[..., i] = pred.cpu().detach().numpy()*y_std+y_m\n",
    "\n",
    "\n",
    "    reals = batch[..., 1:].cpu().detach().numpy()*y_std + y_m\n",
    "\n",
    "    print(preds.shape)\n",
    "    print(reals.shape)\n",
    "\n",
    "    wd = []\n",
    "    for pred, real in zip(preds, reals):  # iterate over all data points (as far as I know, this cannot be batched)\n",
    "        wd.append(wasserstein_distance_nd(pred.T, real.T))\n",
    "\n",
    "print('Mean Wasserstein distance between real and predicted:', np.mean(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bifurc_env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
