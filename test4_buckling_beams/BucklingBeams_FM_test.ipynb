{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f32c07c",
   "metadata": {},
   "source": [
    "Load a previously trained model and test it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f89d5b0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, Tensor\n",
    "import torch_geometric as tg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('cuda available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('cuda not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9d7cb",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = '167fac2522fd465f9207c582ada7c716'  # EGNN. Uses symmetric matching.\n",
    "# run_id = '7d5e596c25b44b06bd90c38f51fd3142'  # EGNN, but without symmetric matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = mlflow.tracking.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6fe6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "art_path = mlflow.get_run(run_id).info.artifact_uri[8:]\n",
    "print(art_path)\n",
    "\n",
    "# Fetch the logged artifacts\n",
    "artifacts = client.list_artifacts(run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get logged parameter network_type\n",
    "network_type = client.get_run(run_id).data.params['network_type']\n",
    "print('network_type:', network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211312a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the files with the weights of the model and the parameters needed to initialize it\n",
    "for artifact in artifacts:\n",
    "    if 'model_weights.pt' in artifact.path:\n",
    "        model_path = os.path.join(art_path, artifact.path)\n",
    "        print(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246769c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make sure model definition is imported from the right directory\n",
    "sys.path.insert(0, art_path)\n",
    "\n",
    "# import model definition\n",
    "files = os.listdir(art_path)\n",
    "GNN_definition = [file for file in files if file.startswith(network_type)]\n",
    "if len(GNN_definition) > 1:\n",
    "    raise Exception('Multiple GNN definitions found')\n",
    "elif len(GNN_definition) == 0:\n",
    "    raise Exception('No GNN definition found')\n",
    "print('GNN_definition:', GNN_definition[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def = importlib.import_module(GNN_definition[0].split('.')[0])\n",
    "model_def = importlib.reload(model_def)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02569a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flow, self).__init__()\n",
    "        if network_type == 'GNNtimeConv':\n",
    "            # layers =  [(4, 3, 1, 2, 0)]\n",
    "            # node_in, edge_in, message_size, node_out, edge_out:\n",
    "            layers =  [(4, 3, 32, 32, 32),\n",
    "                       (32, 32, 32, 32, 32),\n",
    "                       (32, 32, 1, 2, 0)\n",
    "                       ]\n",
    "\n",
    "            # reuse_layers = (1,)\n",
    "            reuse_layers = (1,1,1)\n",
    "            self.model = model_def.GNN(layers=layers, reuse_layers=reuse_layers).to(device)\n",
    "        elif network_type == 'EGNNtimeConv':\n",
    "            # layers =  [(4, 3, 1, 0, 0)]\n",
    "            layers =  [(4, 3, 32, 32, 32),\n",
    "                       (32, 32, 32, 32, 32),\n",
    "                       (32, 32, 1, 0, 0)\n",
    "                       ]\n",
    "            # reuse_layers = (1,)\n",
    "            reuse_layers = (1,1,1)\n",
    "            self.model = model_def.EGNN(layers=layers, reuse_layers=reuse_layers).to(device)\n",
    "\n",
    "    def forward(self, t, x_t, batch, verbose=False) -> Tensor:\n",
    "        # t: torch.tensor, shape [batch size,], current flow-matching time\n",
    "        # x_t: torch.tensor, shape [batch size, 2, T], current position\n",
    "\n",
    "        x_shift = self.model(batch=batch, current_pos=x_t, tau=t, verbose=verbose)\n",
    "\n",
    "        return x_shift\n",
    "\n",
    "    def step(self, x_t: Tensor, t_start: Tensor, t_end: Tensor, batch) -> Tensor:\n",
    "        # t_start: float, current time\n",
    "        # t_end: float, end time\n",
    "        # x_t: shape [batch size, 2, T], current position\n",
    "\n",
    "        t_start = t_start.expand(x_t.shape[0]).view(-1, 1, 1)\n",
    "        t_end = t_end.expand(x_t.shape[0]).view(-1, 1, 1)\n",
    "\n",
    "        return (x_t + (t_end - t_start)\n",
    "                * self(\n",
    "                    t=(t_start + (t_end - t_start) / 2).view(-1),\n",
    "                    x_t= x_t + self(x_t=x_t, t=t_start.view(-1), batch=batch) * (t_end - t_start) / 2,\n",
    "                    batch=batch\n",
    "                        )\n",
    "                )\n",
    "\n",
    "\n",
    "flow = Flow().to(device)\n",
    "print(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e765fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flow.load_state_dict(torch.load(model_path))\n",
    "print(flow)\n",
    "flow.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222d057",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'path/to/data/folder'  # TODO: set this to your local data folder\n",
    "\n",
    "data_path = os.path.join(data_folder, 'BucklingBeams_data_fullyConnected.pkl')\n",
    "mlflow.log_param('data_path', data_path)\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6857115",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['data_tr', 'data_te']:\n",
    "    for graph in data[key]:\n",
    "        N = graph.N[0].item()\n",
    "\n",
    "        # divide K_i by L_i to get proper scaling\n",
    "        Li = graph.edge_attr[:N, [0]]\n",
    "        # graph.node_attr[0, 3:] /= Li[0]  # divide K_i node 0 by L_0\n",
    "        # graph.node_attr[1:N, 3:] /= 0.5*(Li[:N-1] + Li[1:])   # divide K_i nodes 1-N by 1/2(L_i+L_i-1)\n",
    "\n",
    "        # move L_i feature to its own tensor (should be treated separately because of scaling)\n",
    "        graph.L_init = graph.edge_attr[:, 0]\n",
    "        graph.edge_attr = graph.edge_attr[:, 1:]  # remove L_i from edge_attr\n",
    "\n",
    "        graph.L_tot = graph.L_init[:N].sum().reshape(1,) # total length of beam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071725c9",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_type = client.get_run(run_id).data.params['prior_type']\n",
    "print('prior_type:', prior_type)\n",
    "\n",
    "if prior_type == 'Prior_wide':\n",
    "    mu_phi, std_phi = -0.00030389729903857826, 0.014231439025614998\n",
    "    mu_eps, std_eps = 2.0113846990910993e-05, 0.008196196348061435\n",
    "    a, b = 4.042343191342216e-05, 0.0025632507\n",
    "    prior = model_def.Prior_wide(std_phi=std_phi, mu_eps=mu_eps, std_eps=std_eps, a=a, b=b)\n",
    "elif prior_type == 'Prior':\n",
    "    lamb = 94.09494942436929\n",
    "    mu_eps = 2.0113846990910993e-05\n",
    "    std_eps = 0.008196196348061435\n",
    "    prior = model_def.Prior(lamb=lamb, mu_eps=mu_eps, std_eps=std_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader3 = tg.loader.DataLoader(data['data_te'], batch_size=2)\n",
    "\n",
    "n_steps = 64\n",
    "time_steps = torch.linspace(0, 1.0, n_steps+1).to(device)\n",
    "\n",
    "n_samples = 50\n",
    "preds = np.empty((n_samples, 3, 2, 200))  # (n_samples, n_nodes, dim, n_timesteps)\n",
    "\n",
    "# find one example with N=2\n",
    "with torch.no_grad():\n",
    "    for j, batch in enumerate(test_loader3):\n",
    "        if batch.N[0].item() != 2:\n",
    "            print('Skipping batch with N != 2, N =', batch.N[0].item())\n",
    "            continue\n",
    "\n",
    "        print('Batch:', j)\n",
    "        print(batch)\n",
    "        batch = batch.to(device)\n",
    "        for s in range(n_samples):\n",
    "\n",
    "\n",
    "            e = batch.edge_index\n",
    "            L_init_temp = batch.L_init[e[0] == e[1]-1]  # use only the beam element edges, not the virtual ones, not the reversed ones\n",
    "\n",
    "            x = prior(batch.N, batch.d, batch.node_attr[..., :3], L_init_temp, batch.batch, batch.L_tot)\n",
    "\n",
    "            real = batch.pos[batch.batch==0, ..., 0].cpu().detach().numpy()  # final position (target)\n",
    "\n",
    "            for i in range(n_steps):\n",
    "                # print(f'Step {i}/{n_steps}')\n",
    "\n",
    "                x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], batch=batch)\n",
    "\n",
    "            pred = x[batch.batch==0].cpu().detach().numpy()\n",
    "            preds[s] = pred\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef0f0d",
   "metadata": {},
   "source": [
    "## Bifurcation diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47900249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3), dpi=200)\n",
    "\n",
    "# colors = plt.get_cmap('viridis')(np.linspace(0, 1, real.shape[0]))\n",
    "colors = plt.get_cmap('tab10')(np.arange(real.shape[0]))\n",
    "d = (real[-1,1,0] - real[-1,1,:])/real[-1,1,0]*100\n",
    "for s in range(n_samples):\n",
    "    pred = preds[s]\n",
    "\n",
    "    for j in range(pred.shape[0]):\n",
    "        plt.plot(d, pred[j, 0, :].T, linestyle='--', color=colors[j], alpha=0.2)\n",
    "\n",
    "for j in range(real.shape[0]):\n",
    "    color = plt.get_cmap('viridis')(j / real.shape[0])\n",
    "    plt.plot(d, real[j, 0, :].T, color=colors[j], linewidth=2)\n",
    "    plt.plot(d, -real[j, 0, :].T, color=colors[j], linewidth=2, label=f'Node {j}')\n",
    "\n",
    "fmt = '%.0f%%' # Format you want the ticks, e.g. '40%'\n",
    "xticks = mtick.FormatStrFormatter(fmt)\n",
    "ax.xaxis.set_major_formatter(xticks)\n",
    "\n",
    "\n",
    "plt.xlabel('d')\n",
    "plt.ylabel('x-coordinate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722d288",
   "metadata": {},
   "source": [
    "## Plot entire trajectory, all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d272b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3), dpi=200)\n",
    "\n",
    "for s in range(n_samples):\n",
    "    pred = preds[s]\n",
    "\n",
    "    for t in np.arange(pred.shape[-1], step=10):  # loop over time steps\n",
    "        # print('t =', t)\n",
    "        for j in range(len(pred)-1): # loop over segments\n",
    "            ax.plot(pred[j:j+2, 0, t], pred[j:j+2, 1, t],\n",
    "                    color=plt.cm.viridis(t / (pred.shape[-1] - 1)))\n",
    "        ax.scatter(pred[:, 0, t], pred[:, 1, t], s=3, color='black')\n",
    "    ax.set_title(r'predictions')\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f7033f",
   "metadata": {},
   "source": [
    "## Plot real and predicted, one figure per time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbd168",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [20, 100, 150, 199]:  # loop over time steps\n",
    "    print('t =', t)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4,3), dpi=200)\n",
    "\n",
    "    # plot real\n",
    "    ax.plot(real[:, 0, t], real[:, 1, t], color='tab:blue', linewidth=2, label='Real', marker='o', markersize=5, zorder=10)\n",
    "    ax.plot(-real[:, 0, t], real[:, 1, t], color='tab:blue', linewidth=2, marker='o', markersize=5, zorder=10)\n",
    "\n",
    "    # plot predictions\n",
    "    for s in range(n_samples):\n",
    "        pred = preds[s]\n",
    "\n",
    "        ax.plot(pred[:, 0, t], pred[:, 1, t], color='tab:orange', linewidth=2, label=s*'_'+'Predicted', marker='o', markersize=5, alpha=0.3)\n",
    "\n",
    "    # Plot start\n",
    "    ax.plot(real[:, 0, 0], real[:, 1, 0], color='gray', marker='o', markersize=5, label='Initial')\n",
    "\n",
    "    ax.set_title(f'd = {t/(199)*100:.0f}%')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # get x limits\n",
    "    lims = ax.get_xlim()\n",
    "    if lims[0] > -1 or lims[1] < 1:\n",
    "        plt.xlim([-1, 1])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    if t == 199:\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9dbd0",
   "metadata": {},
   "source": [
    "# Illustration: plot real, 2 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, [t1, t2] in enumerate([[0, 20], [20, 40], [40, 60]]):  # loop over time steps\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4,3), dpi=200)\n",
    "\n",
    "    for i, [t, c, l] in enumerate(zip([t1, t2],\n",
    "                                      ['tab:blue', 'tab:orange'],\n",
    "                                      ['t', 't+1'])):\n",
    "        # plot real\n",
    "        ax.plot(real[:, 0, t], real[:, 1, t], color=c, linewidth=2,\n",
    "                marker='o', markersize=5, zorder=10, label=l)\n",
    "        ax.plot(-real[:, 0, t], real[:, 1, t], color=c, linewidth=2,\n",
    "                marker='o', markersize=5, zorder=10)\n",
    "\n",
    "    # Plot start\n",
    "    ax.plot(real[:, 0, 0], real[:, 1, 0], color='gray', marker='o', markersize=5, label='Initial')\n",
    "\n",
    "    ax.set_title(f'$d$ from {t1/(199)*100:.0f}% to {t2/(199)*100:.0f}%')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "\n",
    "    # add extra margin to axes limits\n",
    "\n",
    "    # get x limits\n",
    "    lims = ax.get_xlim()\n",
    "    if lims[0] > -0.8 or lims[1] < 0.8:\n",
    "        plt.xlim([-0.8, 0.8])\n",
    "    # else:\n",
    "    #     plt.xlim([lims[0]-0.4, lims[1]+0.4])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # if j == 0:\n",
    "    #     plt.legend(loc='lower right')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01262de1",
   "metadata": {},
   "source": [
    "# Wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_type = client.get_run(run_id).data.params['prior_type']\n",
    "print('prior_type:', prior_type)\n",
    "\n",
    "if prior_type == 'Prior_wide':\n",
    "    mu_phi, std_phi = -0.00030389729903857826, 0.014231439025614998\n",
    "    mu_eps, std_eps = 2.0113846990910993e-05, 0.008196196348061435\n",
    "    a, b = 4.042343191342216e-05, 0.0025632507\n",
    "    prior = model_def.Prior_wide(std_phi=std_phi, mu_eps=mu_eps, std_eps=std_eps, a=a, b=b)\n",
    "elif prior_type == 'Prior':\n",
    "    lamb = 94.09494942436929\n",
    "    mu_eps = 2.0113846990910993e-05\n",
    "    std_eps = 0.008196196348061435\n",
    "    prior = model_def.Prior(lamb=lamb, mu_eps=mu_eps, std_eps=std_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance_nd\n",
    "\n",
    "test_loader3 = tg.loader.DataLoader(data['data_te'], batch_size=64)\n",
    "\n",
    "n_steps = 8\n",
    "time_steps = torch.linspace(0, 1.0, n_steps+1).to(device)\n",
    "\n",
    "T = data['data_te'][0].pos.shape[-2]\n",
    "print('T =', T)\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "wd = []\n",
    "with torch.no_grad():\n",
    "    for j, batch in enumerate(test_loader3):\n",
    "        print('Batch:', j)\n",
    "        print(batch)\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # create 100 predictions per node\n",
    "        preds = np.zeros((len(batch.pos), 2, T, n_samples)) # shape (n_nodes, dim, T, n_samples)\n",
    "\n",
    "        for s in range(n_samples):\n",
    "\n",
    "\n",
    "            e = batch.edge_index\n",
    "            L_init_temp = batch.L_init[e[0] == e[1]-1]  # use only the beam element edges, not the virtual ones, not the reversed ones\n",
    "\n",
    "            x = prior(batch.N, batch.d, batch.node_attr[..., :3], L_init_temp, batch.batch, batch.L_tot)\n",
    "\n",
    "            real = batch.pos[batch.batch==0, ..., 0].cpu().detach().numpy()  # final position (target)\n",
    "\n",
    "            for i in range(n_steps):\n",
    "                # print(f'Step {i}/{n_steps}')\n",
    "\n",
    "                x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], batch=batch)\n",
    "\n",
    "            pred = x.cpu().detach().numpy()\n",
    "            preds[..., s] = pred\n",
    "\n",
    "        reals = batch.pos.cpu().detach().numpy() # shape (n_nodes, dim, T, n_solutions)\n",
    "\n",
    "        bbatch = batch.batch.cpu().detach().numpy()\n",
    "\n",
    "        print('Calculate Wasserstein distance')\n",
    "        for i in range(batch.batch.max()):  # iterate over all graphs in the batch\n",
    "            pred = preds[bbatch==i].reshape(-1, n_samples)  # shape (n_nodes×dim×T, n_samples)\n",
    "            real = reals[bbatch==i].reshape(-1, 2)  # shape (n_nodes×dim×T, n_solutions)\n",
    "            wd.append(wasserstein_distance_nd(pred.T, real.T))\n",
    "\n",
    "print('Mean Wasserstein distance:', np.mean(wd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bifurc_env4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
